{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google-research/google-research.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcSCJie-Ewic",
        "outputId": "1acd7eed-0b5e-4126-98ac-9bd634c936b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'google-research'...\n",
            "remote: Enumerating objects: 73342, done.\u001b[K\n",
            "remote: Counting objects: 100% (458/458), done.\u001b[K\n",
            "remote: Compressing objects: 100% (336/336), done.\u001b[K\n",
            "remote: Total 73342 (delta 143), reused 403 (delta 104), pack-reused 72884\u001b[K\n",
            "Receiving objects: 100% (73342/73342), 596.49 MiB | 29.80 MiB/s, done.\n",
            "Resolving deltas: 100% (44830/44830), done.\n",
            "Updating files: 100% (18352/18352), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/google-research/tsmixer/tsmixer_basic/data_loader.py /content"
      ],
      "metadata": {
        "id": "mq1zwOBkFTdd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/google-research/tsmixer/tsmixer_basic/models /content"
      ],
      "metadata": {
        "id": "nZjfkzw0FeRo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xxdU6ZskD_BM"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from data_loader import TSFDataLoader  # You may need to adapt this import\n",
        "import models  # You may need to adapt this import\n",
        "from models import tsmixer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args_data = 'word_embedding_covid_pred'\n",
        "args_model = 'tsmixer'\n",
        "args_delete_checkpoint = False\n",
        "args_train_epochs = 100\n",
        "args_batch_size = 32\n",
        "args_seq_len = 5\n",
        "args_pred_len = 5\n",
        "args_feature_type = 'M'\n",
        "args_target = 'num_patients'\n",
        "args_norm_type = 'B'\n",
        "args_activation = 'relu'\n",
        "args_dropout = 0.05\n",
        "args_n_block = 2\n",
        "args_ff_dim = 2048\n",
        "args_kernel_size = 4\n",
        "args_learning_rate = 0.0001\n",
        "args_checkpoint_dir = './checkpoints/'\n",
        "args_patience = 5\n",
        "args_result_path = 'result.csv'"
      ],
      "metadata": {
        "id": "OtQ78GTr-9R4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  exp_id = f'{args_data}_{args_feature_type}_{args_model}_sl{args_seq_len}_pl{args_pred_len}_lr{args_learning_rate}_nt{args_norm_type}_{args_activation}_nb{args_n_block}_dp{args_dropout}_fd{args_ff_dim}'\n",
        "\n",
        "  # load datasets\n",
        "  data_loader = TSFDataLoader(\n",
        "      args_data,\n",
        "      args_batch_size,\n",
        "      args_seq_len,\n",
        "      args_pred_len,\n",
        "      args_feature_type,\n",
        "      args_target,\n",
        "  )\n",
        "  train_data = data_loader.get_train()\n",
        "  val_data = data_loader.get_val()\n",
        "  test_data = data_loader.get_test()\n",
        "\n",
        "  # train model\n",
        "  if 'tsmixer' in args_model:\n",
        "    build_model = tsmixer.build_model\n",
        "    model = build_model(\n",
        "        input_shape=(args_seq_len, data_loader.n_feature),\n",
        "        pred_len=args_pred_len,\n",
        "        norm_type=args_norm_type,\n",
        "        activation=args_activation,\n",
        "        dropout=args_dropout,\n",
        "        n_block=args_n_block,\n",
        "        ff_dim=args_ff_dim,\n",
        "        target_slice=data_loader.target_slice,\n",
        "    )\n",
        "  elif args_model == 'full_linear':\n",
        "    model = models.full_linear.Model(\n",
        "        n_channel=data_loader.n_feature,\n",
        "        pred_len=args_pred_len,\n",
        "    )\n",
        "  elif args_model == 'cnn':\n",
        "    model = models.cnn.Model(\n",
        "        n_channel=data_loader.n_feature,\n",
        "        pred_len=args_pred_len,\n",
        "        kernel_size=args_kernel_size,\n",
        "    )\n",
        "  else:\n",
        "    raise ValueError(f'Model not supported: {args_model}')\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=args_learning_rate)\n",
        "  model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "  checkpoint_path = os.path.join(args_checkpoint_dir, f'{exp_id}_best')\n",
        "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=checkpoint_path,\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=True,\n",
        "  )\n",
        "  early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
        "      monitor='val_loss', patience=args_patience\n",
        "  )\n",
        "  start_training_time = time.time()\n",
        "  history = model.fit(\n",
        "      train_data,\n",
        "      epochs=args_train_epochs,\n",
        "      validation_data=val_data,\n",
        "      callbacks=[checkpoint_callback, early_stop_callback],\n",
        "  )\n",
        "  end_training_time = time.time()\n",
        "  elasped_training_time = end_training_time - start_training_time\n",
        "  print(f'Training finished in {elasped_training_time} secconds')\n",
        "\n",
        "  # evaluate best model\n",
        "  best_epoch = np.argmin(history.history['val_loss'])\n",
        "  model.load_weights(checkpoint_path)\n",
        "  test_result = model.evaluate(test_data)\n",
        "  if args_delete_checkpoint:\n",
        "    for f in glob.glob(checkpoint_path + '*'):\n",
        "      os.remove(f)\n",
        "\n",
        "  # save result to csv\n",
        "  data = {\n",
        "      'data': [args_data],\n",
        "      'model': [args_model],\n",
        "      'seq_len': [args_seq_len],\n",
        "      'pred_len': [args_pred_len],\n",
        "      'lr': [args_learning_rate],\n",
        "      'mse': [test_result[0]],\n",
        "      'mae': [test_result[1]],\n",
        "      'val_mse': [history.history['val_loss'][best_epoch]],\n",
        "      'val_mae': [history.history['val_mae'][best_epoch]],\n",
        "      'train_mse': [history.history['loss'][best_epoch]],\n",
        "      'train_mae': [history.history['mae'][best_epoch]],\n",
        "      'training_time': elasped_training_time,\n",
        "      'norm_type': args_norm_type,\n",
        "      'activation': args_activation,\n",
        "      'n_block': args_n_block,\n",
        "      'dropout': args_dropout,\n",
        "  }\n",
        "  if 'TSMixer' in args_model:\n",
        "    data['ff_dim'] = args_ff_dim\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  if os.path.exists(args_result_path):\n",
        "    df.to_csv(args_result_path, mode='a', index=False, header=False)\n",
        "  else:\n",
        "    df.to_csv(args_result_path, mode='w', index=False, header=True)"
      ],
      "metadata": {
        "id": "v-caE6ywSD9g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh7oLibHNMlm",
        "outputId": "499b2ef6-eed7-4ddc-a68f-8a040bfa379f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3353 - mae: 1.0946\n",
            "Epoch 1: val_loss improved from inf to 13.28625, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.3353 - mae: 1.0946 - val_loss: 13.2862 - val_mae: 2.4406\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0617 - mae: 1.0646\n",
            "Epoch 2: val_loss improved from 13.28625 to 11.05750, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 3.0617 - mae: 1.0646 - val_loss: 11.0575 - val_mae: 2.2649\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8513 - mae: 1.0451\n",
            "Epoch 3: val_loss improved from 11.05750 to 9.31535, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 423ms/step - loss: 2.8513 - mae: 1.0451 - val_loss: 9.3153 - val_mae: 2.1224\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6409 - mae: 1.0252\n",
            "Epoch 4: val_loss improved from 9.31535 to 7.96931, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 2.6409 - mae: 1.0252 - val_loss: 7.9693 - val_mae: 2.0076\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4804 - mae: 1.0102\n",
            "Epoch 5: val_loss improved from 7.96931 to 6.90897, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.4804 - mae: 1.0102 - val_loss: 6.9090 - val_mae: 1.9130\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3105 - mae: 0.9950\n",
            "Epoch 6: val_loss improved from 6.90897 to 6.07041, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 457ms/step - loss: 2.3105 - mae: 0.9950 - val_loss: 6.0704 - val_mae: 1.8364\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1705 - mae: 0.9823\n",
            "Epoch 7: val_loss improved from 6.07041 to 5.41800, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 2.1705 - mae: 0.9823 - val_loss: 5.4180 - val_mae: 1.7758\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0558 - mae: 0.9740\n",
            "Epoch 8: val_loss improved from 5.41800 to 4.89827, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 2.0558 - mae: 0.9740 - val_loss: 4.8983 - val_mae: 1.7257\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9419 - mae: 0.9664\n",
            "Epoch 9: val_loss improved from 4.89827 to 4.49144, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 1.9419 - mae: 0.9664 - val_loss: 4.4914 - val_mae: 1.6856\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8523 - mae: 0.9569\n",
            "Epoch 10: val_loss improved from 4.49144 to 4.17398, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 607ms/step - loss: 1.8523 - mae: 0.9569 - val_loss: 4.1740 - val_mae: 1.6532\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7848 - mae: 0.9528\n",
            "Epoch 11: val_loss improved from 4.17398 to 3.92000, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 1.7848 - mae: 0.9528 - val_loss: 3.9200 - val_mae: 1.6265\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7366 - mae: 0.9516\n",
            "Epoch 12: val_loss improved from 3.92000 to 3.72474, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 1.7366 - mae: 0.9516 - val_loss: 3.7247 - val_mae: 1.6068\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6786 - mae: 0.9432\n",
            "Epoch 13: val_loss improved from 3.72474 to 3.57408, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 606ms/step - loss: 1.6786 - mae: 0.9432 - val_loss: 3.5741 - val_mae: 1.5918\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6416 - mae: 0.9415\n",
            "Epoch 14: val_loss improved from 3.57408 to 3.45586, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 1.6416 - mae: 0.9415 - val_loss: 3.4559 - val_mae: 1.5796\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5852 - mae: 0.9322\n",
            "Epoch 15: val_loss improved from 3.45586 to 3.36110, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 1.5852 - mae: 0.9322 - val_loss: 3.3611 - val_mae: 1.5706\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5598 - mae: 0.9284\n",
            "Epoch 16: val_loss improved from 3.36110 to 3.28180, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 1.5598 - mae: 0.9284 - val_loss: 3.2818 - val_mae: 1.5631\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5152 - mae: 0.9207\n",
            "Epoch 17: val_loss improved from 3.28180 to 3.21620, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 1.5152 - mae: 0.9207 - val_loss: 3.2162 - val_mae: 1.5565\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4840 - mae: 0.9133\n",
            "Epoch 18: val_loss improved from 3.21620 to 3.16328, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 1.4840 - mae: 0.9133 - val_loss: 3.1633 - val_mae: 1.5507\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4714 - mae: 0.9122\n",
            "Epoch 19: val_loss improved from 3.16328 to 3.11665, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 1.4714 - mae: 0.9122 - val_loss: 3.1166 - val_mae: 1.5451\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4630 - mae: 0.9094\n",
            "Epoch 20: val_loss improved from 3.11665 to 3.07506, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 1.4630 - mae: 0.9094 - val_loss: 3.0751 - val_mae: 1.5399\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4347 - mae: 0.8991\n",
            "Epoch 21: val_loss improved from 3.07506 to 3.03936, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 636ms/step - loss: 1.4347 - mae: 0.8991 - val_loss: 3.0394 - val_mae: 1.5357\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4168 - mae: 0.8946\n",
            "Epoch 22: val_loss improved from 3.03936 to 3.01017, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 1.4168 - mae: 0.8946 - val_loss: 3.0102 - val_mae: 1.5325\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4022 - mae: 0.8910\n",
            "Epoch 23: val_loss improved from 3.01017 to 2.98646, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 1.4022 - mae: 0.8910 - val_loss: 2.9865 - val_mae: 1.5300\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3647 - mae: 0.8779\n",
            "Epoch 24: val_loss improved from 2.98646 to 2.96457, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 1.3647 - mae: 0.8779 - val_loss: 2.9646 - val_mae: 1.5270\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3569 - mae: 0.8734\n",
            "Epoch 25: val_loss improved from 2.96457 to 2.94418, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 1.3569 - mae: 0.8734 - val_loss: 2.9442 - val_mae: 1.5233\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3208 - mae: 0.8625\n",
            "Epoch 26: val_loss improved from 2.94418 to 2.92716, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 1.3208 - mae: 0.8625 - val_loss: 2.9272 - val_mae: 1.5193\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3064 - mae: 0.8584\n",
            "Epoch 27: val_loss improved from 2.92716 to 2.91418, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 1.3064 - mae: 0.8584 - val_loss: 2.9142 - val_mae: 1.5160\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2829 - mae: 0.8479\n",
            "Epoch 28: val_loss improved from 2.91418 to 2.90534, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 1.2829 - mae: 0.8479 - val_loss: 2.9053 - val_mae: 1.5137\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2506 - mae: 0.8383\n",
            "Epoch 29: val_loss improved from 2.90534 to 2.89931, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 1.2506 - mae: 0.8383 - val_loss: 2.8993 - val_mae: 1.5122\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2267 - mae: 0.8310\n",
            "Epoch 30: val_loss improved from 2.89931 to 2.89451, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 1.2267 - mae: 0.8310 - val_loss: 2.8945 - val_mae: 1.5116\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2113 - mae: 0.8231\n",
            "Epoch 31: val_loss improved from 2.89451 to 2.88998, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 1.2113 - mae: 0.8231 - val_loss: 2.8900 - val_mae: 1.5119\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1902 - mae: 0.8144\n",
            "Epoch 32: val_loss improved from 2.88998 to 2.88167, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 421ms/step - loss: 1.1902 - mae: 0.8144 - val_loss: 2.8817 - val_mae: 1.5124\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1837 - mae: 0.8098\n",
            "Epoch 33: val_loss improved from 2.88167 to 2.87197, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 1.1837 - mae: 0.8098 - val_loss: 2.8720 - val_mae: 1.5124\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1591 - mae: 0.8014\n",
            "Epoch 34: val_loss improved from 2.87197 to 2.86003, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1591 - mae: 0.8014 - val_loss: 2.8600 - val_mae: 1.5118\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1179 - mae: 0.7881\n",
            "Epoch 35: val_loss improved from 2.86003 to 2.84731, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 1.1179 - mae: 0.7881 - val_loss: 2.8473 - val_mae: 1.5107\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1171 - mae: 0.7874\n",
            "Epoch 36: val_loss improved from 2.84731 to 2.83519, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 1.1171 - mae: 0.7874 - val_loss: 2.8352 - val_mae: 1.5094\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0985 - mae: 0.7793\n",
            "Epoch 37: val_loss improved from 2.83519 to 2.82488, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 1.0985 - mae: 0.7793 - val_loss: 2.8249 - val_mae: 1.5058\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0750 - mae: 0.7701\n",
            "Epoch 38: val_loss improved from 2.82488 to 2.80837, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 1.0750 - mae: 0.7701 - val_loss: 2.8084 - val_mae: 1.4998\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0639 - mae: 0.7670\n",
            "Epoch 39: val_loss improved from 2.80837 to 2.79132, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 604ms/step - loss: 1.0639 - mae: 0.7670 - val_loss: 2.7913 - val_mae: 1.4912\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0583 - mae: 0.7625\n",
            "Epoch 40: val_loss improved from 2.79132 to 2.76712, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 567ms/step - loss: 1.0583 - mae: 0.7625 - val_loss: 2.7671 - val_mae: 1.4806\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0245 - mae: 0.7507\n",
            "Epoch 41: val_loss improved from 2.76712 to 2.73507, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 1.0245 - mae: 0.7507 - val_loss: 2.7351 - val_mae: 1.4692\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0199 - mae: 0.7469\n",
            "Epoch 42: val_loss improved from 2.73507 to 2.69871, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 1.0199 - mae: 0.7469 - val_loss: 2.6987 - val_mae: 1.4575\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9939 - mae: 0.7416\n",
            "Epoch 43: val_loss improved from 2.69871 to 2.65663, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 603ms/step - loss: 0.9939 - mae: 0.7416 - val_loss: 2.6566 - val_mae: 1.4447\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9811 - mae: 0.7350\n",
            "Epoch 44: val_loss improved from 2.65663 to 2.61148, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 0.9811 - mae: 0.7350 - val_loss: 2.6115 - val_mae: 1.4333\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9574 - mae: 0.7281\n",
            "Epoch 45: val_loss improved from 2.61148 to 2.57049, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.9574 - mae: 0.7281 - val_loss: 2.5705 - val_mae: 1.4227\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9546 - mae: 0.7228\n",
            "Epoch 46: val_loss improved from 2.57049 to 2.53444, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.9546 - mae: 0.7228 - val_loss: 2.5344 - val_mae: 1.4145\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9567 - mae: 0.7250\n",
            "Epoch 47: val_loss improved from 2.53444 to 2.50219, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.9567 - mae: 0.7250 - val_loss: 2.5022 - val_mae: 1.4066\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9295 - mae: 0.7128\n",
            "Epoch 48: val_loss improved from 2.50219 to 2.47110, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.9295 - mae: 0.7128 - val_loss: 2.4711 - val_mae: 1.4004\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9125 - mae: 0.7096\n",
            "Epoch 49: val_loss improved from 2.47110 to 2.44245, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 623ms/step - loss: 0.9125 - mae: 0.7096 - val_loss: 2.4424 - val_mae: 1.3930\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8973 - mae: 0.7042\n",
            "Epoch 50: val_loss improved from 2.44245 to 2.40630, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 560ms/step - loss: 0.8973 - mae: 0.7042 - val_loss: 2.4063 - val_mae: 1.3830\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8775 - mae: 0.6943\n",
            "Epoch 51: val_loss improved from 2.40630 to 2.37239, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 387ms/step - loss: 0.8775 - mae: 0.6943 - val_loss: 2.3724 - val_mae: 1.3733\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8685 - mae: 0.6916\n",
            "Epoch 52: val_loss improved from 2.37239 to 2.33644, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.8685 - mae: 0.6916 - val_loss: 2.3364 - val_mae: 1.3618\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8567 - mae: 0.6858\n",
            "Epoch 53: val_loss improved from 2.33644 to 2.29794, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 399ms/step - loss: 0.8567 - mae: 0.6858 - val_loss: 2.2979 - val_mae: 1.3491\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8513 - mae: 0.6801\n",
            "Epoch 54: val_loss improved from 2.29794 to 2.25831, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.8513 - mae: 0.6801 - val_loss: 2.2583 - val_mae: 1.3346\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8434 - mae: 0.6776\n",
            "Epoch 55: val_loss improved from 2.25831 to 2.22907, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 410ms/step - loss: 0.8434 - mae: 0.6776 - val_loss: 2.2291 - val_mae: 1.3255\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8334 - mae: 0.6769\n",
            "Epoch 56: val_loss improved from 2.22907 to 2.20879, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.8334 - mae: 0.6769 - val_loss: 2.2088 - val_mae: 1.3210\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8138 - mae: 0.6689\n",
            "Epoch 57: val_loss improved from 2.20879 to 2.18984, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.8138 - mae: 0.6689 - val_loss: 2.1898 - val_mae: 1.3179\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8231 - mae: 0.6703\n",
            "Epoch 58: val_loss improved from 2.18984 to 2.17379, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.8231 - mae: 0.6703 - val_loss: 2.1738 - val_mae: 1.3148\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7907 - mae: 0.6594\n",
            "Epoch 59: val_loss improved from 2.17379 to 2.16136, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 400ms/step - loss: 0.7907 - mae: 0.6594 - val_loss: 2.1614 - val_mae: 1.3122\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7701 - mae: 0.6510\n",
            "Epoch 60: val_loss improved from 2.16136 to 2.14257, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.7701 - mae: 0.6510 - val_loss: 2.1426 - val_mae: 1.3051\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7578 - mae: 0.6453\n",
            "Epoch 61: val_loss improved from 2.14257 to 2.12507, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7578 - mae: 0.6453 - val_loss: 2.1251 - val_mae: 1.2976\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7814 - mae: 0.6524\n",
            "Epoch 62: val_loss improved from 2.12507 to 2.10704, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.7814 - mae: 0.6524 - val_loss: 2.1070 - val_mae: 1.2893\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7496 - mae: 0.6387\n",
            "Epoch 63: val_loss improved from 2.10704 to 2.08548, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7496 - mae: 0.6387 - val_loss: 2.0855 - val_mae: 1.2784\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7328 - mae: 0.6368\n",
            "Epoch 64: val_loss improved from 2.08548 to 2.05841, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.7328 - mae: 0.6368 - val_loss: 2.0584 - val_mae: 1.2657\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7289 - mae: 0.6337\n",
            "Epoch 65: val_loss improved from 2.05841 to 2.04076, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.7289 - mae: 0.6337 - val_loss: 2.0408 - val_mae: 1.2584\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7100 - mae: 0.6214\n",
            "Epoch 66: val_loss improved from 2.04076 to 2.03314, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 397ms/step - loss: 0.7100 - mae: 0.6214 - val_loss: 2.0331 - val_mae: 1.2568\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7234 - mae: 0.6263\n",
            "Epoch 67: val_loss improved from 2.03314 to 2.02938, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 0.7234 - mae: 0.6263 - val_loss: 2.0294 - val_mae: 1.2553\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7086 - mae: 0.6207\n",
            "Epoch 68: val_loss improved from 2.02938 to 2.01644, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 565ms/step - loss: 0.7086 - mae: 0.6207 - val_loss: 2.0164 - val_mae: 1.2499\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6998 - mae: 0.6170\n",
            "Epoch 69: val_loss improved from 2.01644 to 1.99662, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 0.6998 - mae: 0.6170 - val_loss: 1.9966 - val_mae: 1.2380\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7012 - mae: 0.6142\n",
            "Epoch 70: val_loss improved from 1.99662 to 1.99280, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 548ms/step - loss: 0.7012 - mae: 0.6142 - val_loss: 1.9928 - val_mae: 1.2336\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6824 - mae: 0.6085\n",
            "Epoch 71: val_loss improved from 1.99280 to 1.97846, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 553ms/step - loss: 0.6824 - mae: 0.6085 - val_loss: 1.9785 - val_mae: 1.2237\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6806 - mae: 0.6075\n",
            "Epoch 72: val_loss improved from 1.97846 to 1.95592, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 0.6806 - mae: 0.6075 - val_loss: 1.9559 - val_mae: 1.2087\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6780 - mae: 0.6048\n",
            "Epoch 73: val_loss improved from 1.95592 to 1.92213, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 562ms/step - loss: 0.6780 - mae: 0.6048 - val_loss: 1.9221 - val_mae: 1.1855\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6622 - mae: 0.5978\n",
            "Epoch 74: val_loss improved from 1.92213 to 1.90157, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 0.6622 - mae: 0.5978 - val_loss: 1.9016 - val_mae: 1.1709\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6574 - mae: 0.5982\n",
            "Epoch 75: val_loss improved from 1.90157 to 1.88578, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 0.6574 - mae: 0.5982 - val_loss: 1.8858 - val_mae: 1.1728\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6501 - mae: 0.5939\n",
            "Epoch 76: val_loss improved from 1.88578 to 1.86807, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 580ms/step - loss: 0.6501 - mae: 0.5939 - val_loss: 1.8681 - val_mae: 1.1705\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6445 - mae: 0.5914\n",
            "Epoch 77: val_loss improved from 1.86807 to 1.83742, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 0.6445 - mae: 0.5914 - val_loss: 1.8374 - val_mae: 1.1607\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6456 - mae: 0.5891\n",
            "Epoch 78: val_loss improved from 1.83742 to 1.80225, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 558ms/step - loss: 0.6456 - mae: 0.5891 - val_loss: 1.8023 - val_mae: 1.1494\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6318 - mae: 0.5845\n",
            "Epoch 79: val_loss improved from 1.80225 to 1.77322, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.6318 - mae: 0.5845 - val_loss: 1.7732 - val_mae: 1.1393\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6164 - mae: 0.5789\n",
            "Epoch 80: val_loss improved from 1.77322 to 1.74398, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 561ms/step - loss: 0.6164 - mae: 0.5789 - val_loss: 1.7440 - val_mae: 1.1256\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6177 - mae: 0.5789\n",
            "Epoch 81: val_loss improved from 1.74398 to 1.71905, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.6177 - mae: 0.5789 - val_loss: 1.7190 - val_mae: 1.1067\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6044 - mae: 0.5722\n",
            "Epoch 82: val_loss did not improve from 1.71905\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.6044 - mae: 0.5722 - val_loss: 1.7195 - val_mae: 1.0915\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5942 - mae: 0.5661\n",
            "Epoch 83: val_loss did not improve from 1.71905\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.5942 - mae: 0.5661 - val_loss: 1.7429 - val_mae: 1.0896\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6041 - mae: 0.5690\n",
            "Epoch 84: val_loss did not improve from 1.71905\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 0.6041 - mae: 0.5690 - val_loss: 1.7469 - val_mae: 1.0879\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6085 - mae: 0.5703\n",
            "Epoch 85: val_loss did not improve from 1.71905\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.6085 - mae: 0.5703 - val_loss: 1.7219 - val_mae: 1.0830\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5988 - mae: 0.5669\n",
            "Epoch 86: val_loss improved from 1.71905 to 1.67864, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.5988 - mae: 0.5669 - val_loss: 1.6786 - val_mae: 1.0668\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5987 - mae: 0.5662\n",
            "Epoch 87: val_loss improved from 1.67864 to 1.61758, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.5987 - mae: 0.5662 - val_loss: 1.6176 - val_mae: 1.0455\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5881 - mae: 0.5609\n",
            "Epoch 88: val_loss improved from 1.61758 to 1.56871, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 0.5881 - mae: 0.5609 - val_loss: 1.5687 - val_mae: 1.0294\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5941 - mae: 0.5651\n",
            "Epoch 89: val_loss improved from 1.56871 to 1.52549, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.5941 - mae: 0.5651 - val_loss: 1.5255 - val_mae: 1.0057\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5699 - mae: 0.5538\n",
            "Epoch 90: val_loss improved from 1.52549 to 1.51981, saving model to ./checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.5699 - mae: 0.5538 - val_loss: 1.5198 - val_mae: 0.9976\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5760 - mae: 0.5561\n",
            "Epoch 91: val_loss did not improve from 1.51981\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.5760 - mae: 0.5561 - val_loss: 1.5496 - val_mae: 1.0006\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5554 - mae: 0.5452\n",
            "Epoch 92: val_loss did not improve from 1.51981\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.5554 - mae: 0.5452 - val_loss: 1.5766 - val_mae: 1.0121\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5625 - mae: 0.5480\n",
            "Epoch 93: val_loss did not improve from 1.51981\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.5625 - mae: 0.5480 - val_loss: 1.6032 - val_mae: 1.0083\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5420 - mae: 0.5414\n",
            "Epoch 94: val_loss did not improve from 1.51981\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.5420 - mae: 0.5414 - val_loss: 1.5869 - val_mae: 0.9811\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5474 - mae: 0.5413\n",
            "Epoch 95: val_loss did not improve from 1.51981\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.5474 - mae: 0.5413 - val_loss: 1.5454 - val_mae: 0.9522\n",
            "Training finished in 65.88108849525452 secconds\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.7249 - mae: 1.2955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/result.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "turUJanh8S0M",
        "outputId": "0105424f-1d3c-40dc-8753-a3c3bd000ace"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        data    model  seq_len  pred_len      lr       mse  \\\n",
              "0  word_embedding_covid_pred  tsmixer        5         5  0.0001  2.724948   \n",
              "\n",
              "        mae   val_mse   val_mae  train_mse  train_mae  training_time  \\\n",
              "0  1.295467  1.519811  0.997578   0.569863   0.553838      65.881088   \n",
              "\n",
              "  norm_type activation  n_block  dropout  \n",
              "0         B       relu        2     0.05  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7634f8bf-64e9-4642-9da7-c3d45aa132e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>model</th>\n",
              "      <th>seq_len</th>\n",
              "      <th>pred_len</th>\n",
              "      <th>lr</th>\n",
              "      <th>mse</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>train_mse</th>\n",
              "      <th>train_mae</th>\n",
              "      <th>training_time</th>\n",
              "      <th>norm_type</th>\n",
              "      <th>activation</th>\n",
              "      <th>n_block</th>\n",
              "      <th>dropout</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>word_embedding_covid_pred</td>\n",
              "      <td>tsmixer</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>2.724948</td>\n",
              "      <td>1.295467</td>\n",
              "      <td>1.519811</td>\n",
              "      <td>0.997578</td>\n",
              "      <td>0.569863</td>\n",
              "      <td>0.553838</td>\n",
              "      <td>65.881088</td>\n",
              "      <td>B</td>\n",
              "      <td>relu</td>\n",
              "      <td>2</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7634f8bf-64e9-4642-9da7-c3d45aa132e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7634f8bf-64e9-4642-9da7-c3d45aa132e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7634f8bf-64e9-4642-9da7-c3d45aa132e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best.data-00000-of-00001\n",
        "/content/checkpoints/word_embedding_covid_pred_M_tsmixer_sl5_pl5_lr0.0001_ntB_relu_nb2_dp0.05_fd2048_best.index\n",
        "/content/checkpoints/checkpoint"
      ],
      "metadata": {
        "id": "LBzqbdX88fbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}